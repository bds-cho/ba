\section{Introduction}
\label{cha:intro}

% BACKGROUND AND MOTIVATION
Cloud computing delivers on-demand resources like servers, storage, and databases via the Internet, eliminating the need for physical infrastructure and enabling flexibility and scalability. Its adoption has surged in the past decade due to the emergence of data-intensive applications and improved connectivity \cite{}. Amazon Web Services (AWS), a leader in cloud computing, pioneered various cloud models and controls over 30\% of the global market as of 2023, driven by its innovation and broad service portfolio \cite{}.

% PROBLEM STATEMENT
Applications in cloud environments typically consist of compute and datastore service instances that interact frequently. For example, AWS Elastic Compute Cloud (EC2) is often used for backend processing, while AWS Relational Database Service (RDS) handles structured data storage. Communication between these services is a critical aspect of cloud application architecture, and network latencies significantly influence overall performance and user experience, particularly in latency-sensitive applications such as e-commerce, real-time analytics, and gaming \cite{}.

AWS offers latency insights for datastore services from both service-side and client-side perspectives. However, it remains unclear how client-side latency varies across different AWS compute services. For instance, does the EC2-RDS pair perform differently compared to Lambda-RDS? AWS provides numerous configurations and tools for optimizing service interactions, yet the specific latency characteristics between services can vary depending on network setup, service proximity, caching strategies, and service-specific characteristics. As organizations seek efficient and performant cloud architectures, understanding the latency dynamics between these services is essential for making informed architectural decisions.

Despite the critical role of latency in cloud-based systems, publicly available empirical data on latency characteristics between AWS compute and datastore services remains limited. This thesis aims to fill this knowledge gap by providing an initial benchmark for access latency metrics between key AWS compute and datastore service pairs, specifically EC2, and Lambda paired with RDS, DynamoDB, and Simple Storage Service (S3).

% THESIS STRUCTURE
We therefore make the following contributions in this thesis:
\begin{enumerate}
	\item We address the identified knowledge gap by proposing a benchmark design, detailed in \cref{cha:approach}.
	\item We evaluate the proposed approach through experimentation on AWS compute and datastore service pairs, with implementation and results presented in \cref{cha:implementation,cha:results}.
\end{enumerate}
